---
title: "Writing conda recipes"
subtitle: "Practical"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    self-contained: true
    seal: false
    css: ["default", "template.css"]
    nature:
      slideNumberFormat: ""
      #ratio: "16:12"
---


layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Using conda]

.Large[Practical session]

.Large[Per Unneberg]

.Large[2022-11-17]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
					  warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Exercises

## Objective 

Show basic conda usage, how to write a conda recipe and how to switch
between conda environments in jupyter notebooks.

## Setup

```{bash setup, eval=FALSE }
mkdir -p exercises
cd exercises
```

---


class: center, middle

.HUGE[Conda environments]



---

# Conda environments - common commands

## Objective

Show basic conda commands, how to create environments, and how to
switch between them.

--

## Listing environments

List environments with `conda env list` (or `conda info --envs`):

```{bash conda-envs-common-commands-list, eval=FALSE}
conda env list
```
````{verbatim}
# conda environments:
#
base                     /home/peru/miniconda3
lectures                 /home/peru/miniconda3/envs/lectures
lectures2             *  /home/peru/miniconda3/envs/lectures2
````

- `base` is the starting environment
- the `*` indicates the active environment

---

# Conda environments - common commands

## Creating / removing environments

```{bash conda-envs-create-remove , eval=FALSE}
mamba create --name=myenv python=3.8 numpy
mamba env remove --name=myenv
```

--

Let's create an environment for `samtools`:

```{bash conda-envs-create-samtools, eval=FALSE }
mamba create --name=samtools samtools
```

```{bash conda-envs-create-samtools-eval, echo=FALSE, cache=TRUE }
if conda env list --json | grep samtools > /dev/null 2>&1; then echo >/dev/null ; else mamba create -y --name=samtools samtools; fi
```

--

## Activating / deactivating environments


```{bash conda-envs-activate, eval=FALSE }
command -v samtools
conda activate samtools
command -v samtools
conda deactivate
command -v samtools
```

---

# Conda environments - common commands

## Installing packages

```{bash conda-envs-install-bioawk-samtools, eval=FALSE }
mamba install -n samtools bioawk
```

--

## Listing installed packages

```{bash conda-envs-list-installed, eval=FALSE }
conda list
conda list --explicit
```

`--explicit` lists package with URL that can then be used with `conda
create --file`

--

## Exporting environments

```{bash conda-envs-export, eval=FALSE }
conda env export
conda env export --from-history
conda list --explicit
```

`--from-history` builds environment spec from explicit specs
(excluding dependencies) in history

---

class: center, middle

.HUGE[Writing conda recipes]

---

# Writing Conda recipes

## Objective

Go through steps needed to write a Bioconda recipe for a tool you
would like to add. We will be working with tools that are available on
Bioconda so there is a "solution" for comparison.

--

## Bioconda packages<sup>1</sup>

.small[
````{verbatim}
$ tree -A recipes/bioawk
recipes/bioawk/
├── build.sh
└── meta.yaml
````
]

--

- `meta.yaml` is required
--

- optional:
--

  - `build.sh`
--

  - (small) test files
--

  - license file


.footnote[
.small[[1] cf https://bioconda.github.io/tutorials/gcb2020.html]]


---

# Important meta.yaml sections


- `package`: name and version
- `source`: url and SHA256/MD5 checksums
- `build`: build number, platforms to skip, “noarch” information
- `requirements`: packages for building, linking, running
- `test`: commands/imports
- `about`: webpage, license, summary of what the package does
- `extras`: comments, maintainers, etc.

---

# Example 1 - bioawk

## Objective

Write recipe for bioawk whose source code is found at
https://github.com/lh3/bioawk

--

## Setup

Start by creating a directory for the recipe:

```{bash, eval=FALSE }
mkdir -p bioawk
```

```{bash, eval=TRUE , echo=FALSE}
mkdir -p exercises/bioawk
```


and open the file `bioawk/meta.yaml` in an editor. 

---

# 1. Edit the meta file

Following conda documentation<sup>1</sup>, we need to complete the
following template:

.small[
````{verbatim, lang="YAML" }
package:
  name:
  version:

source:
  url:
  sha256:

requirements:
  build:
	-

  run:
	-

test:
  commands:
	-

about:
  home:
````
]

.footnote[
.small[[1] https://docs.conda.io/projects/conda-build/en/latest/user-guide/tutorials/build-pkgs.html#editing-the-meta-yaml-file]]

---

# 2. Get tarball metadata

The conda package will be built from a tarball that we download from
the repo. We need to provide the recipe with a .green[url] and a
.green[sha256] checksum.

Click on the releases link to the right on the repo home page. This
should bring you to
[https://github.com/lh3/bioawk/releases](https://github.com/lh3/bioawk/releases)

--

Copy the tarball link [Source code
(tar.gz)](https://github.com/lh3/bioawk/archive/refs/tags/v1.0.tar.gz)
to set the URL to download with `wget` and pipe to `sha256sum`:

.small[
```{bash e1-tarball-sha256-echo, eval=FALSE }
URL=https://github.com/lh3/bioawk/archive/refs/tags/v1.0.tar.gz
wget -O- ${URL} -o /dev/null | sha256sum
```
]

--

.small[
```{bash e1-tarball-sha256-eval, echo=FALSE }
URL=https://github.com/lh3/bioawk/archive/refs/tags/v1.0.tar.gz
if [ ! -e exercises/bioawk.sha256sum.txt ]; then
	wget -O- ${URL} -o /dev/null | sha256sum > exercises/bioawk.sha256sum.txt
fi
cat exercises/bioawk.sha256sum.txt
```
]

--

Now we can add this to the .green[source] section in the meta.yaml
file, along with .green[package name] and .green[version] number:


.small[
````{verbatim}
package:
  name: bioawk
  version: "1.0"

source:
  url: https://github.com/lh3/bioawk/archive/v1.0.tar.gz
  sha256: 5cbef3f39b085daba45510ff450afcf943cfdfdd483a546c8a509d3075ff51b5
````
]
---


# 3. Clone the repo

Next we need to know how to compile the package and gather information
about dependencies and requirements.

--

Start by cloning the repo:

```{bash, eval=FALSE }
git clone git@github.com:lh3/bioawk.git bioawk.git
ls bioawk.git | head -5
```

```{bash list-bioawk, echo=FALSE}
if [ ! -e exercises/bioawk.git ]; then
	git clone git@github.com:lh3/bioawk.git exercises/bioawk.git
fi
ls exercises/bioawk.git | head -5
```
--

There is a README.md that hopefully provides installation
instructions, and a Makefile that contains instructions to compile the
package. If we scroll through the former, we will find the following
information:

```{bash e1-head-readme, echo=FALSE }
head -12 exercises/bioawk.git/README.md | tail -3
```

--

.green[bison] and .green[libz] are two dependencies.

---

# Add dependencies

Add the dependencies .green[bison] and .green[libz] to the
.green[requirements] section, .green[build] keyword:

```{bash e1-write-meta-1, echo=FALSE }
cat >exercises/bioawk/meta.yaml <<EOL
package:
  name: bioawk
  version: "1.0"

source:
  url: https://github.com/lh3/bioawk/archive/v1.0.tar.gz
  sha256: 5cbef3f39b085daba45510ff450afcf943cfdfdd483a546c8a509d3075ff51b5

requirements:
  build:
    - zlib
    - bison
EOL
```

```{bash e1-read-meta-no-test, eval=FALSE, code=readLines("exercises/bioawk/meta.yaml") }

```


---

# 4. Inspect build instructions

Examine the Makefile and look for the .green[bioawk] target; linked
packages are defined with the .green[-l] option:

````{verbatim}
bioawk:ytab.o $(OFILES)
	$(CC) $(CFLAGS) ytab.o $(OFILES) $(ALLOC) -o $@ -lm -lz
````

--

No obvious additional dependencies (.green[-lm] links the math library
that should be available by default, .green[-lz] links .green[zlib]).
However, .green[zlib] is used at runtime to process gzipped files so
should be added to the .green[build:run] section. Also, since we use
the .green[gcc]<sup>1</sup> compiler to build, we add that too:


````{verbatim}
requirements:
  build:
	- {{ compiler('c') }}
	- zlib
	- bison
  run:
    - zlib
````

.footnote[.small[[1] https://bioconda.github.io/contributor/guidelines.html#c-c]]

---

# Adding a test

For Bioconda recipes, "*an adequate test must be included in the
recipe*" (this is good advice anyway). This would give the following
meta.yaml file:

--

```{bash e1-write-meta-with-test, echo=FALSE }
cat >exercises/bioawk/meta.yaml <<EOL
package:
  name: bioawk
  version: "1.0"

source:
  url: https://github.com/lh3/bioawk/archive/v1.0.tar.gz
  sha256: 5cbef3f39b085daba45510ff450afcf943cfdfdd483a546c8a509d3075ff51b5

requirements:
  build:
    - {{ compiler('c') }}
    - zlib
    - bison
  run:
    - zlib

test:
  commands:
    - echo "hello world" | bioawk '{print}'
EOL
```

```{bash e1-read-meta-with-test, eval=FALSE, code=readLines("exercises/bioawk/meta.yaml") }

```



---

# Build file

Finally we need to write a build file `bioawk/build.sh`. From the
conda documentation<sup>1</sup>, "*anything that your build script
copies into the $PREFIX or %PREFIX% folder will be included in your
output package*".

Unfortunately I chose a difficult package in the sense that it depends
on zlib<sup>2</sup>: "*the location of zlib often has to be specified
in the build.sh script*"

--

```{bash e1-write-build-file, echo=FALSE }
cat >exercises/bioawk/build.sh <<EOL
export CFLAGS="$CFLAGS -I\$PREFIX/include"
export LDFLAGS="$LDFLAGS -L\$PREFIX/lib"

make
mkdir -p \$PREFIX/bin
cp bioawk \$PREFIX/bin
EOL
chmod +x exercises/bioawk/build.sh
```

```{bash e1-read-build-file, eval=FALSE, code=readLines("exercises/bioawk/build.sh") }

```
--

Now try building the recipe with:

```{bash e1-build-recipe, eval=FALSE}
conda build bioawk
```


.footnote[

.small[[1] https://docs.conda.io/projects/conda-build/en/stable/resources/build-scripts.html]

.small[[2] https://bioconda.github.io/contributor/troubleshooting.html#zlib-errors]

]



---

# Official recipe - how did we do?


.small[
````{verbatim}
package:
  name: bioawk
  version: "1.0"

source:
  url: https://github.com/lh3/bioawk/archive/v1.0.tar.gz
  sha256: 5cbef3f39b085daba45510ff450afcf943cfdfdd483a546c8a509d3075ff51b5

build:
  number: 0

requirements:
  build:
    - make
    - {{ compiler('c') }}
  host:
    - zlib
    - bison
    - m4
  run:
    - zlib

test:
  commands:
    - echo "hw" | bioawk '{print}'

about:
  home: https://github.com/lh3/bioawk
  license: Free software license (https://github.com/lh3/bioawk/blob/master/README.awk#L1)
  summary: BWK awk modified for biological data
````
]

.small[See https://docs.conda.io/projects/conda-build/en/stable/resources/define-metadata.html#requirements-section for distinction between .green[requirements:build] and .green[requirements:host]]

---

# Official build file

````{verbatim lang="bash"}
#!/bin/bash
export LIBRARY_PATH="$PREFIX/lib"

make CC=$CC CFLAGS="-g -Wall -O2 -I$PREFIX/include -L$PREFIX/lib"

mkdir -p $PREFIX/bin
cp bioawk $PREFIX/bin
````

---

# Example 2 - cutadapt

.scriptsize[
````{verbatim}
{% set version = "4.1" %}

package:
  name: cutadapt
  version: {{ version }}

source:
  url: https://files.pythonhosted.org/packages/a3/30/4a889a6916d7480c153774777e634b89865f95cb02f2c3209762c7ef984b/cutadapt-4.1.tar.gz
  sha256: be745ff24adfb4a3eaf715dfad0e2ccdfad7792ef00c1122adf4fbf3aed9227b

build:
  number: 1
  script: "{{ PYTHON }} -m pip install . --no-deps -vv"
  skip: True  # [py27 or py36]

requirements:
  build:
    - {{ compiler('c') }}
  host:
    - pip
    - python
    - cython
    - setuptools-scm
  run:
    - python
    - xopen >=1.2.0
    - dnaio >=0.7.0
    - dataclasses >=0.7  # [py36]

test:
  imports:
    - cutadapt
  commands:
    - cutadapt --version

about:
  home: https://cutadapt.readthedocs.io/
  license: MIT
  summary: Trim adapters from high-throughput sequencing reads

extra:
  recipe-maintainers:
    - marcelm
  identifiers:
    - biotools:cutadapt
    - doi:10.14806/ej.17.1.200
````
]

???

NB: no build script - taken care of in `build:script` section

---

# Example 3 - r-rblast

.scriptsize[
````{verbatim}
package:
  name: r-rblast
  version: "0.99.1"
source:
  url:
    - https://github.com/mhahsler/rBLAST/archive/5cbc5039705e45c83d88c324c4f2a64dfc63e4e1.tar.gz
  md5: 5773ffb34b208af1d7999518c645728a
build:
  number: 6
  rpaths:
    - lib/R/lib/
    - lib/
requirements:
  host:
    - r-base
    - bioconductor-biostrings
  run:
    - r-base
    - bioconductor-biostrings
    - blast
test:
  commands:
    - $R -e "library('rBLAST')" # [not win]
    - "\"%R%\" -e \"library('rBLAST')\"" # [win]
about:
  home: https://github.com/mhahsler/rBLAST
  license: GPL3
  summary: 'Seamlessly interfaces the Basic Local Alignment Search Tool (BLAST) to search genetic sequence data bases. This work was partially supported by grant no. R21HG005912 from the National Human Genome Research Institute.'
extra:
  recipe-maintainers:
    - MathiasHaudgaard
    - FrodePedersen
    - ArneKr
    - johanneskoester
    - bgruening
    - daler
    - jdblischak
````
]

Build script:
.small[
````{verbatim}
$R CMD INSTALL --build .
````
]

---

# Bioconda resources - summary and resources

## Bioconda guidelines for recipes

https://bioconda.github.io/contributor/guidelines.html

## Conda documentation

### Metadata

https://docs.conda.io/projects/conda-build/en/stable/resources/define-metadata.html

---

class: center, middle

.HUGE[Conda and notebooks]

---


# Using conda in notebooks

## Objective

Show how to switch between conda environments in jupyter notebooks.

--


In `base` conda environment, install the following:

```{bash install-jupyter-notebook, eval=FALSE}
mamba install -c conda-forge notebook
mamba install -c conda-forge nb_conda_kernels
mamba install -c conda-forge jupyter_contrib_nbextensions
```

This enables running `jupyter-notebook` from the base environment and
switch between conda environments in the notebook.

--

Why bother?

--

Imagine we want to run two different versions of `pyfastx` and that
we wanted to choose between them in the notebook. Start by creating
two environments:

```{bash pyfastx-0.8.4, eval=FALSE }
mamba create -n pyfastx-0.8.4 pyfastx=0.8.4
mamba create -n pyfastx-0.7.0 pyfastx=0.7.0
```

---

# 1. Show conda environments in notebook with nb_conda_kernels

Activate your `base` environment and install `notebook` and
`nb_conda_kernels`:

```{bash install_nb_conda_kernels, eval=FALSE }
conda install -c conda-forge notebook
conda install -c conda-forge nb_conda_kernels
```

Fire up `jupyter-notebook` and list the available kernels in the `New`
dropdown list.

--

You should not be able to see `pyfastx-0.8.4` or `pyfastx-0.7.0`.

???

The following url shows how to setup jupyter notebook so that one can
switch conda environments in the notebook:

https://towardsdatascience.com/how-to-set-up-anaconda-and-jupyter-notebook-the-right-way-de3b7623ea4a

The following post shows two ways of setting up conda and notebooks:

https://stackoverflow.com/questions/58068818/how-to-use-jupyter-notebooks-in-a-conda-environment

Either 1. run jupyter server and kernel inside environment or 2.
create a kernel *from the environment*, if one for some reason doesn't
want to install jupyter_core and notebook in every single environment
(e.g. only having it in base environment)

--

You need to install `ipykernel` in the environment to make it show:

```{bash install-ipykernel-in-pyfastx-0.8.4 , eval=FALSE}
mamba install -n pyfastx-0.8.4 ipykernel
```

Restart the `jupyter-notebook` session and list the available kernels
again.

--

Now `pyfastx-0.8.4` should be visible among the options.

---

# 2. Add a jupyter kernel by registering a conda environment

The alternative to listing a conda environment is to create a jupyter
kernel by registering the environment. The benefit could be that it is
easy to **register** and **deregister** environment kernels in order
to keep the list tidy.

--

Activate the `pyfastx-0.7.0` environment and install `ipykernel`.

```{bash activate-pyfastx-0.7.0, eval=FALSE }
conda activate pyfastx-0.7.0
mamba install ipykernel
```


Then, a so-called *kernelspec*<sup>1</sup> can be registered with the
following command:

```{bash register-kernelspec, eval=FALSE }
ipython kernel install --user --name=pyfastx-0.7.0 --display-name=pyfastx-0.7.0
```



.footnote[.small[ [1] https://jupyter-client.readthedocs.io/en/latest/kernels.html#kernel-specs]]

---

# 2. Add a jupyter kernel by registering a conda environment

You can list installed kernelspecs with 

```{bash list-kernelspecs, eval=FALSE}
jupyter kernelspec list | grep pyfastx
```

--

Deactivate the environment, relaunch `jupyter-notebook` from base
environment and see if `pyfastx-0.7.0` is found in the list.

--

You can deregister a kernelspec as follows:

```{bash deregister-kernelspec, eval=FALSE }
jupyter kernelspec remove pyfastx-0.7.0
```

---

# Using kernels in quarto notebooks

On a final note, you can also use jupyter kernels in quarto notebooks
(cf https://quarto.org/docs/guide/) as defined in the yaml header:

.small[
````{verbatim}
---
title: "matplotlib demo"
format:
  html:
    code-fold: true
jupyter: python3
---

For a demonstration of a line plot on a polar axis, see @fig-polar.

```{python}
#| label: fig-polar
#| fig-cap: "A line plot on a polar axis"

import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```
````
]



---


# Summary

- we have used conda to create isolated software environments
- we have looked at the basics of creating conda recipes
- we have seen how to switch between conda environments in jupyter
  notebooks
